{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teach the Teacher workshop \n",
    "\n",
    "*25 January 2021*\n",
    "\n",
    "\n",
    "## A guessing game\n",
    "\n",
    "The code below contains the code for a simple game in which the user needs to guess a number in between 1 and 50.\n",
    "\n",
    "The standard function input() can be used to request a value from the user. The function int() converts the input into an integer, if possible. The code also makes use of ‘for’ and of ‘while’. When the user enters a value which is too low or too high, this information is communicated to the user via a print statement.\n",
    "\n",
    "To run the code in the cell below, place the cursur in the cell and click on [Shift] + [Enter]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "max = 50\n",
    "number = random.randint(0,max)\n",
    "\n",
    "guess = int( input( f\"Guess a number in between 1 and {max}: \") )\n",
    "\n",
    "while guess != number:\n",
    "\n",
    "    if guess > number:\n",
    "        print(\"Lower!\")\n",
    "    elif guess < number:\n",
    "        print(\"Higher!\")\n",
    "    guess = int( input(\"Guess again ... \\n\") )\n",
    "\n",
    "print(\"The correct number is indeed {}.\".format(number) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpora and Open Data\n",
    "\n",
    "* [Project Gutenberg](https://www.gutenberg.org/)\n",
    "* [Distant Reading E-COST](https://github.com/distantreading/distantreading.github.io)\n",
    "* [DBNL](https://dbnl.nl/)\n",
    "* [Text Creation Partnership](https://github.com/textcreationpartnership/Texts)\n",
    "* [WikiData](https://www.wikidata.org/)\n",
    "* [Folger Shakespeare DIgital Library](https://shakespeare.folger.edu/download/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulk downloads\n",
    "\n",
    "Files can obviously be downloaded manually via their URL. \n",
    "\n",
    "See, for example, https://www.gutenberg.org/ebooks/98"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the number of files to acquire becomes very large, it can be more efficient to write a program which can download files in bulk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "gutenberg_files = {\n",
    "    'http://www.gutenberg.org/files/158/158-0.txt':'Emma',\n",
    "    'http://www.gutenberg.org/files/161/161-0.txt':'Sense and Sensibility',\n",
    "    'http://www.gutenberg.org/files/1342/1342-0.txt':'Pride and Prejudice'\n",
    "}\n",
    "\n",
    "\n",
    "for url in gutenberg_files:\n",
    "    print(\"Downloading \" + gutenberg_files[url] + \" ...\")\n",
    "    response = requests.get(url)\n",
    "    title = re.sub( r'\\s+' , '_' ,  gutenberg_files[url] )\n",
    "\n",
    "    if response:\n",
    "        response.encoding = 'utf-8'\n",
    "        lines = re.split( r'\\n' , response.text )\n",
    "        flag = 0 \n",
    "        full_text = ''\n",
    "        \n",
    "        for line in lines:\n",
    "            if flag == 1:\n",
    "                full_text += line + '\\n'\n",
    "            \n",
    "            if re.search( r'\\*{3,}\\s+START\\s+OF\\s+TH(E|IS)\\s+PROJECT\\s+GUTENBERG\\s+EBOOK' ,  str(line) , re.IGNORECASE ):\n",
    "                flag = 1\n",
    "            if re.search( r'\\*{3,}\\s+END\\s+OF\\s+TH(E|IS)\\s+PROJECT\\s+GUTENBERG\\s+EBOOK' ,  str(line) , re.IGNORECASE ):\n",
    "                flag = 0\n",
    "        full_text = full_text.strip()\n",
    "        if re.search( r'^Produced by' , full_text , re.IGNORECASE ):\n",
    "            full_text = full_text[ full_text.index('\\n') : len(full_text) ]\n",
    "\n",
    "            \n",
    "        out = open( title , 'w' , encoding = 'utf-8')\n",
    "        out.write( full_text.strip() )\n",
    "        out.close()\n",
    "\n",
    "print('\\nDone!')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below downloads files which are listed in [a CSV file](https://raw.githubusercontent.com/peterverhaar/introduction_to_dh/main/gutenberg_metadata.csv): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "github = 'https://raw.githubusercontent.com/peterverhaar/introduction_to_dh/main/'\n",
    "\n",
    "\n",
    "md = pd.read_csv( github + 'gutenberg_metadata.csv')\n",
    "\n",
    "for index,row in md.iterrows():\n",
    "   \n",
    "    if re.search( r'Dickens' , str( row['author'] ) , re.IGNORECASE ):\n",
    "        print( f\"{row['author']}\\n{row['title']}\\n{row['url']}\\n\\n\" )\n",
    "    \n",
    "    '''\n",
    "    if re.search( r'Gothic' , str( row['subject'] ) , re.IGNORECASE ):\n",
    "        print( f\"{row['author']}\\n{row['title']}\\n{row['url']}\\n\\n\" )\n",
    "    '''    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See, for example: https://en.wikipedia.org/w/api.php?action=opensearch&search=leiden&limit=30&format=json \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "\n",
    "baseURL = 'https://en.wikipedia.org/w/api.php?action=opensearch'\n",
    "search_term = \"leiden\"\n",
    "search_term = re.sub( '\\s+' , '%20' , search_term )\n",
    "\n",
    "limit = 30\n",
    "format = 'json'\n",
    "\n",
    "apiCall = '{}&search={}&limit={}&format={}'.format( baseURL, search_term , limit , format )\n",
    "print( f'URL of the API call: { apiCall } \\n')\n",
    "\n",
    "responseData = requests.get( apiCall )\n",
    "\n",
    "wikiResults = responseData.json()\n",
    "\n",
    "\n",
    "for i in range( 0 , len(wikiResults[1]) ):\n",
    "    print( 'Title: ' + wikiResults[1][i] )\n",
    "    print( 'Tagline: ' + wikiResults[2][i] )\n",
    "    print( 'Url: ' + wikiResults[3][i] + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenStreetMap API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "import string\n",
    "from os.path import isfile, join , isdir\n",
    "import os\n",
    "\n",
    "addresses = '''\n",
    "Arsenaalstraat 1, Leiden\n",
    "Witte Singel 27, Leiden\n",
    "Wassenaarseweg 52, Leiden\n",
    "Leiden Nonnensteeg 1\n",
    "'''\n",
    "\n",
    "addressesList = re.split( r'\\n' , addresses.strip() )\n",
    "\n",
    "\n",
    "\n",
    "for a in addressesList:\n",
    "    url = 'https://nominatim.openstreetmap.org/search?q='+ a + '&format=xml'\n",
    "    url = re.sub( '\\s+' , '%20' , url )\n",
    "\n",
    "    response = requests.get( url )\n",
    "    root = ET.fromstring( response.text )\n",
    "    el = root.findall('place')\n",
    "    \n",
    "    count = 0\n",
    "    if el is not None:\n",
    "        for place in el:\n",
    "            count += 1\n",
    "            lat = place.attrib['lat']\n",
    "            lon = place.attrib['lon']\n",
    "            if count == 1:\n",
    "                print( '{}: {},{}'.format( a, lat , lon ) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goodreads API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "#isbn = '1841156736'\n",
    "isbn = '9780140181067'\n",
    "\n",
    "baseUrl = 'https://www.goodreads.com/book/isbn/'\n",
    "key = 'yZUIiWVAZOHzCFlFwIOTXA'\n",
    "\n",
    "apiCall = '{}{}?key={}'.format( baseUrl , isbn , key )\n",
    "\n",
    "print(apiCall)\n",
    "\n",
    "response = requests.get( apiCall )\n",
    "\n",
    "\n",
    "root = ET.fromstring(response.text)\n",
    "\n",
    "title = root.find( 'book/title' ).text\n",
    "author = root.find( 'book/authors/author/name' ).text\n",
    "date = root.find( 'book/publication_year' ).text\n",
    "averageRating = root.find( 'book/average_rating' ).text\n",
    "\n",
    "reviews = root.find( 'book/work/reviews_count' ).text\n",
    "ratingsSum = int( root.find( 'book/work/ratings_sum' ).text )\n",
    "ratingsCount = int( root.find( 'book/work/ratings_count' ).text )\n",
    "\n",
    "print( f'Title: {title}' )\n",
    "print( f'Author: {author}' )\n",
    "print( f'Date: {date}' )\n",
    "print( f'Average rating: {averageRating}' )\n",
    "print( f'Number of reviews: {reviews}' )\n",
    "print( f'Number of ratings: {ratingsSum}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "#isbn = '1841156736'\n",
    "isbn = '9780140181067'\n",
    "\n",
    "baseUrl = 'https://www.goodreads.com/book/isbn/'\n",
    "key = 'yZUIiWVAZOHzCFlFwIOTXA'\n",
    "\n",
    "apiCall = '{}{}?key={}'.format( baseUrl , isbn , key )\n",
    "\n",
    "print(apiCall)\n",
    "\n",
    "response = requests.get( apiCall )\n",
    "\n",
    "\n",
    "root = ET.fromstring(response.text)\n",
    "\n",
    "\n",
    "title = root.find( 'book/title' ).text\n",
    "date = root.find( 'book/publication_year' ).text\n",
    "\n",
    "reviews = root.find( 'book/work/reviews_count' ).text\n",
    "ratingsSum = int( root.find( 'book/work/ratings_sum' ).text )\n",
    "ratingsCount = int( root.find( 'book/work/ratings_count' ).text )\n",
    "\n",
    "reviewsWidget = root.find( 'book/reviews_widget' ).text\n",
    "\n",
    "#print(reviewsWidget)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup( reviewsWidget ,\"lxml\")\n",
    "\n",
    "links = soup.find_all(\"iframe\")\n",
    "\n",
    "out = open( f'reviews-{ isbn }.txt' , 'w' )\n",
    "\n",
    "for l in links:\n",
    "    url = l.get(\"src\")\n",
    "    print(f\" {url}\")\n",
    "    for i in range(1,2):\n",
    "        url += '&page=' + str(i)\n",
    "        response = requests.get( url )\n",
    "        if response:\n",
    "            response.encoding = 'utf-8'\n",
    "            soup = BeautifulSoup( response.text ,\"lxml\")\n",
    "            #No reviews found. Showing 0-0 in response.text\n",
    "            reviewLinks = soup.find_all(\"link\")\n",
    "            for r in reviewLinks:\n",
    "                reviewUrl = r.get(\"href\")\n",
    "\n",
    "                if re.search( 'goodreads.*review.*show' , reviewUrl ):\n",
    "                    response = requests.get( reviewUrl )\n",
    "                    if response:\n",
    "                        response.encoding = 'utf-8'\n",
    "                        soup = BeautifulSoup( response.text ,\"lxml\")\n",
    "                        fullText = soup.find( 'div' , itemprop='reviewBody' )\n",
    "                        out.write(fullText.text.strip())\n",
    "                        out.write('\\n\\n')\n",
    "                \n",
    "                    \n",
    "print('Ready!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IIIF\n",
    "\n",
    "Documentation: https://iiif.io/api/image/2.1/\n",
    "\n",
    "The following images (from the collection of the National Gallery of Art in Washingtn) are made available via IIIF.\n",
    "\n",
    "https://media.nga.gov/iiif/public/objects/1/0/6/3/8/2/106382-primary-0-nativeres.ptif/full/full/0/default.jpg\n",
    "\n",
    "https://media.nga.gov/iiif/public/objects/4/6/3/0/3/46303-primary-0-nativeres.ptif/full/full/0/default.jpg\n",
    "\n",
    "https://media.nga.gov/iiif/public/objects/1/1/3/8/1138-primary-0-nativeres.ptif/full/full/0/default.jpg\n",
    "\n",
    "\n",
    "Basic structure of URL according to IIIF Image API:\n",
    "{scheme}://{server}{/prefix}/{identifier}/{region}/{size}/{rotation}/{quality}.{format}\n",
    "\n",
    "\n",
    "You can request other manifestations of these images via the following parameters:\n",
    "\n",
    "* Region: Value 'full' or four numbers. In the latter case, the first two numbers define the starting point and the last two number specify the width and the height. \n",
    "* Size: Value 'full or 'two numbers which specify the width and the height. The second number can be omitted\n",
    "* Rotation: Number in between 0 or 359; at the NGA, the values 0, 90, 180 and 270 have been implemented. \n",
    "* Format: values 'default','gray' or 'bitonal', followed by extensons 'jpg', 'png' or 'gif'\n",
    "\n",
    "Sample query: \n",
    "https://media.nga.gov/iiif/public/objects/1/1/3/8/1138-primary-0-nativeres.ptif/20500,2000,20000,5000/500,/90/default.jpg\n",
    "\n",
    "Try to select one of the images listed above and try to request a version of the image with the following properties:\n",
    "*\tBitonal, rotated 90 degrees\n",
    "*\tImage with a width of 150 pixels (default size for a thumbnail)\n",
    "*\tZoom in on a specific detail of the image by specifying a region.\n",
    "\n",
    "You can test the API query in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![IIIF IMAGE](https://media.nga.gov/iiif/public/objects/1/1/3/8/1138-primary-0-nativeres.ptif/20500,2000,20000,5000/500,/0/default.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "\n",
    "soup = \"\"\n",
    "\n",
    "\n",
    "url = 'https://www.imdb.com/chart/top?ref_=ft_250'\n",
    "print(url)\n",
    "\n",
    "\n",
    "response = requests.get( url )\n",
    "soup = BeautifulSoup( response.text ,\"lxml\")\n",
    "\n",
    "\n",
    "movies = soup.find_all('td', {'class': 'titleColumn'})\n",
    "\n",
    "movie_urls = []\n",
    "\n",
    "for m in movies:\n",
    "    children = m.findChildren(\"a\" , recursive=False)\n",
    "    for c in children:\n",
    "        movieTitle = c.text\n",
    "        url = c.get('href')\n",
    "        url = 'http://imdb.com' + url\n",
    "        movie_urls.append( url )\n",
    "        print( '{}: {}'.format( movieTitle , url ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enriching data using APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First, download a CSV file from [the episolarium website](http://ckcc.huygens.knaw.nl/epistolarium/), describing all the letters that have been received by René Descartes. Save the CSV file as 'descartes.csv' in the same directory as this notebook.\n",
    "* Next, run the code below.\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "import requests\n",
    "\n",
    "def remove_brackets(text):\n",
    "    text = re.sub( '(\\[)|(\\])' , '' , text )\n",
    "    return text\n",
    "\n",
    "data = pd.read_csv( 'descartes.csv' , sep = ';' )\n",
    "\n",
    "locations = []\n",
    "locations_coord = dict()\n",
    "\n",
    "for index , row in data.iterrows():\n",
    "    place_sender = remove_brackets(row[3])\n",
    "    place_recipient = remove_brackets(row[5])\n",
    "    locations.append(place_sender)\n",
    "    locations.append(place_recipient)\n",
    "    \n",
    "    \n",
    "for loc in locations:\n",
    "\n",
    "    if loc not in locations_coord:\n",
    "        url = 'https://nominatim.openstreetmap.org/search?q='+ loc + '&format=xml'\n",
    "        url = re.sub( '\\s+' , '%20' , url )\n",
    "\n",
    "        response = requests.get( url )\n",
    "        root = ET.fromstring( response.text )\n",
    "        el = root.findall('place')\n",
    "\n",
    "        count = 0\n",
    "        if el is not None:\n",
    "            for place in el:\n",
    "                count += 1\n",
    "                lat = place.attrib['lat']\n",
    "                lon = place.attrib['lon']\n",
    "                if count == 1:\n",
    "                    locations_coord[ loc ] = ( lat , lon )\n",
    "     \n",
    "\n",
    "    \n",
    "out = open( 'descartes_enriched.csv' , 'w' , encoding = 'utf-8' )\n",
    "\n",
    "out.write('id,date,sender,place,geo_sender,recipient,place,geo_recipient\\n')\n",
    "\n",
    "for index , row in data.iterrows():\n",
    "    \n",
    "    \n",
    "    sender_coord = tuple()\n",
    "    recipient_coord = tuple()\n",
    "    \n",
    "    \n",
    "    if remove_brackets(row[3]) in locations_coord:\n",
    "        sender_coord = locations_coord[remove_brackets(row[3])]\n",
    "    if remove_brackets(row[5]) in locations_coord:\n",
    "        recipient_coord = locations_coord[remove_brackets(row[5])]\n",
    "\n",
    "    out.write( f'\"{row[0]}\",\"{row[1]}\",\"{row[2]}\",\"{row[3]}\",' )\n",
    "    \n",
    "    if sender_coord and not( re.search( r'\\?' , row[3] ) ):\n",
    "        out.write( f'\"{ sender_coord[0]}, {sender_coord[1] }\",' )\n",
    "    else:\n",
    "        out.write( f',' )\n",
    "\n",
    "    out.write( f'\"{row[4]}\",\"{row[5]}\",' )\n",
    "    \n",
    "    if sender_coord and not( re.search( r'\\?' , row[5] ) ):\n",
    "        out.write( f'\"{ recipient_coord[0]}, {recipient_coord[1] }\"' )  \n",
    "    \n",
    "    out.write('\\n')     \n",
    "\n",
    "out.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to generate a map displaying all the locations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = open( 'map.html' , 'w' , encoding = 'utf-8')\n",
    "\n",
    "\n",
    "out.write('''\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "\n",
    "                <title>Correspondence on a map</title>\n",
    "\n",
    "                <meta charset=\"utf-8\" />\n",
    "                <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "\n",
    "                <link rel=\"shortcut icon\" type=\"image/x-icon\" href=\"docs/images/favicon.ico\" />\n",
    "\n",
    "    <link rel=\"stylesheet\" href=\"https://unpkg.com/leaflet@1.7.1/dist/leaflet.css\" integrity=\"sha512-xodZBNTC5n17Xt2atTPuE1HxjVMSvLVW9ocqUKLsCC5CXdbqCmblAshOMAS6/keqq/sMZMZ19scR4PsZChSR7A==\" crossorigin=\"\"/>\n",
    "    <script src=\"https://unpkg.com/leaflet@1.7.1/dist/leaflet.js\" integrity=\"sha512-XQoYMqMTK8LvdxXYG3nZ448hOEQiglfqkJs1NOQV44cWnUrBc8PkAOcXy20w0vlaXaVUearIOBhiXZ5V3ynxwA==\" crossorigin=\"\"></script>\n",
    "\n",
    "\n",
    "\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div id=\"mapid\" style=\"width: 600px; height: 400px;\"></div>\n",
    "<script>\n",
    "\n",
    "                var mymap = L.map('mapid').setView([52.0799838, 4.3113461], 6);\n",
    "\n",
    "                L.tileLayer('https://api.mapbox.com/styles/v1/{id}/tiles/{z}/{x}/{y}?access_token=pk.eyJ1IjoibWFwYm94IiwiYSI6ImNpejY4NXVycTA2emYycXBndHRqcmZ3N3gifQ.rJcFIG214AriISLbB6B5aw', {\n",
    "                                maxZoom: 18,\n",
    "                                attribution: 'Map data &copy; <a href=\"https://www.openstreetmap.org/\">OpenStreetMap</a> contributors, ' +\n",
    "                                                '<a href=\"https://creativecommons.org/licenses/by-sa/2.0/\">CC-BY-SA</a>, ' +\n",
    "                                                'Imagery  <a href=\"https://www.mapbox.com/\">Mapbox</a>',\n",
    "                                id: 'mapbox/streets-v11',\n",
    "                                tileSize: 512,\n",
    "                                zoomOffset: -1\n",
    "                }).addTo(mymap); \n",
    "''')\n",
    "\n",
    "for l in locations_coord:\n",
    "     out.write( f' L.marker([ { locations_coord[l][0] }, { locations_coord[l][1] }  ]).addTo(mymap);  ')\n",
    "\n",
    "out.write(\n",
    "'''\n",
    "</script>\n",
    "\n",
    "\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "\n",
    "''')\n",
    "\n",
    "out.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
